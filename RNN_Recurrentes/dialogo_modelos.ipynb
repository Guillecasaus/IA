{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los tres modelos entrenados\n",
    "model_abascal = load_model(\"model_abascal.keras\")\n",
    "model_sanchez = load_model(\"model_sanchez.keras\")\n",
    "model_casado = load_model(\"model_casado.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, start_string, length=100):\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "    temperature = 0.6  # Ajusta la temperatura según sea necesario\n",
    "\n",
    "    for i in range(length):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el diálogo\n",
    "turns = 5  # Número de rondas de diálogo\n",
    "initial_prompt = \"La situación actual es compleja.\"\n",
    "\n",
    "# Comienza el diálogo con el modelo de Abascal\n",
    "current_speaker = \"abascal\"\n",
    "current_input = initial_prompt\n",
    "\n",
    "# Registro del diálogo\n",
    "dialogue = [f\"Abascal: {current_input}\"]\n",
    "\n",
    "for _ in range(turns):\n",
    "    if current_speaker == \"abascal\":\n",
    "        current_input = generate_response(model_abascal, current_input, length=100)\n",
    "        dialogue.append(f\"Abascal: {current_input}\")\n",
    "        current_speaker = \"sanchez\"\n",
    "    elif current_speaker == \"sanchez\":\n",
    "        current_input = generate_response(model_sanchez, current_input, length=100)\n",
    "        dialogue.append(f\"Sánchez: {current_input}\")\n",
    "        current_speaker = \"Casado\"\n",
    "    elif current_speaker == \"Casado\":\n",
    "        current_input = generate_response(model_casado, current_input, length=100)\n",
    "        dialogue.append(f\"Díaz: {current_input}\")\n",
    "        current_speaker = \"abascal\"\n",
    "\n",
    "# Imprimir el diálogo completo\n",
    "for line in dialogue:\n",
    "    print(line)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
